---

name: CI

on:
  # Triggers the workflow on push or pull request events
  push:
  pull_request:
  release:
    tags:
      - 'v*'
    types: [ published ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  REGISTRY_PATH: ghcr.io/surfscz

jobs:
  Server_tests:
    name: Server tests

    runs-on: ubuntu-latest

    # Test different python versions
    strategy:
      fail-fast: false
      matrix:
        python-version: [ '3.9', '3.11', '3.12', '3.13' ]

    services:
      # How to use MySQL
      mysql:
        image: mysql:5.7
        env:
          MYSQL_ROOT_PASSWORD: root
        ports:
          - 3306:3306
        options: --health-cmd="mysqladmin ping" --health-interval=10s --health-timeout=5s --health-retries=3
      redis:
        # Docker Hub image
        image: redis
        # Set health checks to wait until redis has started
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          # Maps port 6379 on service container to the host
          - 6379:6379

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup mysql server
        run: >
          mysql -uroot -proot -h127.0.0.1 -e "
            DROP DATABASE IF EXISTS sbs_test;
            CREATE DATABASE IF NOT EXISTS sbs_test DEFAULT CHARACTER SET utf8mb4 DEFAULT COLLATE utf8mb4_unicode_ci;
            CREATE DATABASE IF NOT EXISTS sbs_gw0 DEFAULT CHARACTER SET utf8mb4 DEFAULT COLLATE utf8mb4_unicode_ci;
            CREATE DATABASE IF NOT EXISTS sbs_gw1 DEFAULT CHARACTER SET utf8mb4 DEFAULT COLLATE utf8mb4_unicode_ci;
            CREATE DATABASE IF NOT EXISTS sbs_gw2 DEFAULT CHARACTER SET utf8mb4 DEFAULT COLLATE utf8mb4_unicode_ci;
            CREATE DATABASE IF NOT EXISTS sbs_gw3 DEFAULT CHARACTER SET utf8mb4 DEFAULT COLLATE utf8mb4_unicode_ci;
            CREATE USER 'sbs'@'%' IDENTIFIED BY 'sbs';
            GRANT ALL PRIVILEGES ON *.* TO 'sbs'@'%' WITH GRANT OPTION;
          "
      - name: Load SBS schema
        # not strictly necessary, but it avoids running 200+ migrations during tests
        run: |
          mysql -uroot -proot -h127.0.0.1 sbs_gw0 < misc/sbs-db.sql;
          mysql -uroot -proot -h127.0.0.1 sbs_gw1 < misc/sbs-db.sql;
          mysql -uroot -proot -h127.0.0.1 sbs_gw2 < misc/sbs-db.sql;
          mysql -uroot -proot -h127.0.0.1 sbs_gw3 < misc/sbs-db.sql;
      - name: Install SAML2 dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libxml2-dev libxmlsec1-dev libxml2

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
          cache-dependency-path: 'server/requirements/*.txt'

      - name: Display Python version
        run: |
          python -c "import sys; print(sys.version)"
          echo coverage: .${{ matrix.coverage }}.


      - name: Install dependencies
        run: |
          python -m pip install pip setuptools wheel
          pip install --upgrade pip
          pip install -r ./server/requirements/test.txt
          pip install flake8

      # Setup tmate session
      #- name: Setup tmate session
      #  uses: mxschmitt/action-tmate@v3

      - name: Run flake8
        run: |
          cd ./server
          flake8 .

      - name: Run tests with coverage
        run: |
          cd ./server
          coverage run -m pytest test --cov-report xml --cov=server  --junitxml=junit.xml -o junit_family=legacy --numprocesses=4
        timeout-minutes: 20

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
        if: success()

      - name: Upload test results to Codecov
        uses: codecov/test-results-action@v1
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
        if: ${{ !cancelled() }}


  Client_build:
    name: Client build

    runs-on: ubuntu-latest

    steps:
      - name: Run errands
        run: |
          sudo apt -y install curl

      - name: Checkout
        uses: actions/checkout@v4

      - name: Use Node.js 20
        uses: actions/setup-node@v4
        with:
          node-version: "20.8.0"
          cache: "yarn"
          cache-dependency-path: '**/yarn.lock'

      - name: Install dependencies
        shell: bash
        run: |
          source ~/.nvm/nvm.sh
          rm -rf ~/.yarn
          curl -o- -L https://yarnpkg.com/install.sh | bash -s -- --version 1.22.19
          export PATH="$HOME/.yarn/bin:$HOME/.config/yarn/global/node_modules/.bin:$PATH"
          yarn -v
        env:
          VNM_DIR: ~/.nvm

      - name: Run tests and create production build
        shell: bash
        run: |
          cd client
          yarn install
          yarn test
          yarn build
        env:
          CI: true
          VNM_DIR: ~/.nvm
          INLINE_RUNTIME_CHUNK: False
          IMAGE_INLINE_SIZE_LIMIT: 0
        timeout-minutes: 15

      #- name: Setup tmate session
      #  uses: mxschmitt/action-tmate@v3
      - name: Save version info
        run: |
          git log -1 > ./server/api/git.info
          git describe --all --long > ./version.txt

      - name: Create build file
        run: |
          tar -cJ -f /tmp/sbs.tar.xz \
            --transform 's,^\./,sbs/,' --sort=name \
            --owner=0 --group=0 --mode=u=rwX,go=rX \
            --exclude=./client/node_modules --exclude=./.git \
            .

      - name: Show what we are shipping
        run: |
          tar tvJf /tmp/sbs.tar.xz

      - name: Create Artifact
        uses: actions/upload-artifact@v4
        with:
          name: "sbs-build"
          path: "/tmp/sbs.tar.xz"

  # a little but of magic below: we build arm64 and amd64 images on separate native hosts
  # the images are uplaoded by digests and then in a separate task we combine them into a manifest list
  # see https://docs.docker.com/build/ci/github-actions/multi-platform/
  Docker_build:
    name: Build images
    if: >
      github.actor!='dependabot[bot]' &&
      github.event_name!='pull_request' &&
      ( github.ref_type=='tag' || github.ref_type=='branch' )
    needs:
      - "Client_build"

    strategy:
      fail-fast: true
      matrix:
        arch: [ 'amd64', 'arm64' ]
        image: [ 'sbs', 'sbs-server', 'sbs-client' ]
    env:
      containername: "sram-${{ matrix.image }}"
    runs-on: "ubuntu-24.04${{ matrix.arch == 'arm64' && '-arm' || '' }}"
    steps:
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to the Container registry
        uses: docker/login-action@v3
        with:
          registry: "${{ env.REGISTRY }}"
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Checkout
        uses: actions/checkout@v4

      - name: "Extract metadata (tags, labels) for ${{ env.containername }} image"
        id: meta-sbs
        uses: docker/metadata-action@v5
        with:
          images: "${{ env.REGISTRY_PATH }}/${{ env.containername }}"
          #flavor: "suffix=-${{ matrix.arch }}"

      - name: Fetch build
        uses: actions/download-artifact@v4
        with:
          name: "sbs-build"

      - name: Build arch-specific Docker image
        id: build
        uses: docker/build-push-action@v6
        with:
          context: "."
          file: "Dockerfile.${{ matrix.image }}"
          platforms: "linux/${{ matrix.arch }}"
          tags: "${{ env.REGISTRY_PATH }}/${{ env.containername }}"
          labels: ${{ steps.meta-sbs.outputs.labels }}
          outputs: "type=image,push-by-digest=true,name-canonical=true,push=true"
          cache-from: "type=gha"
          cache-to: "type=gha,mode=max"

      - name: Export digest
        run: |
          mkdir -p "${{ runner.temp }}/digests/${{ matrix.image }}/"
          digest="${{ steps.build.outputs.digest }}"
          touch "${{ runner.temp }}/digests/${{ matrix.image }}/${digest#sha256:}"
          echo "Files created:"
          find "${{ runner.temp }}/digests/${{ matrix.image }}"

      - name: Upload digest
        uses: actions/upload-artifact@v4
        with:
          name: "digests__${{ matrix.image }}__${{ matrix.arch }}"
          path: "${{ runner.temp }}/digests/**/*"
          if-no-files-found: error
          retention-days: 1

      # Setup tmate session
      - name: Setup tmate session
        env:
          ACTIONS_STEP_DEBUG: ${{ secrets.ACTIONS_STEP_DEBUG}}
        if: ${{ failure() && env.ACTIONS_STEP_DEBUG == 'true' }}
        uses: mxschmitt/action-tmate@v3
        with:
          limit-access-to-actor: true
        timeout-minutes: 60

  Docker_image:
    name: Merge images
    if: >
      github.actor!='dependabot[bot]' &&
      github.event_name!='pull_request' &&
      ( github.ref_type=='tag' || github.ref_type=='branch' )
    needs:
      - "Docker_build"
      - "Server_tests"
    strategy:
      fail-fast: true
      matrix:
        image: [ 'sbs', 'sbs-server', 'sbs-client' ]
    env:
      containername: "sram-${{ matrix.image }}"
    runs-on: "ubuntu-24.04"
    steps:
      - name: Download digests
        uses: actions/download-artifact@v4
        with:
          path: "${{ runner.temp }}/digests"
          pattern: "digests__*"
          merge-multiple: true

      - name: Log in to the Container registry
        uses: docker/login-action@v3
        with:
          registry: "${{ env.REGISTRY  }}"
          username: "${{ github.actor }}"
          password: "${{ secrets.GITHUB_TOKEN }}"

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: "Extract metadata (tags, labels) for ${{ env.containername }} image"
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: "${{ env.REGISTRY_PATH }}/${{ env.containername }}"
        env:
          DOCKER_METADATA_SET_OUTPUT_ENV: 1

      - name: Create manifest list and push
        working-directory: "${{ runner.temp }}/digests/${{ matrix.image }}"
        run: |
          DIGESTS=$( printf '${{ env.REGISTRY_PATH }}/${{ env.containername }}@sha256:%s ' * )
          TAGS=$( jq -cr '.tags | map("-t " + .) | join(" ")' <<< "$DOCKER_METADATA_OUTPUT_JSON" )

          echo "Creating docker manifest list for ${{ env.containername }}"
          echo "Digests: $DIGESTS"
          echo "Tags: $TAGS"

          docker buildx imagetools create ${TAGS} ${DIGESTS}

      - name: Inspect image
        run: |
          docker buildx imagetools inspect ${{ env.REGISTRY_PATH }}/${{ env.containername }}:${{ steps.meta.outputs.version }}

      # Setup tmate session
      - name: Setup tmate session
        env:
          ACTIONS_STEP_DEBUG: ${{ secrets.ACTIONS_STEP_DEBUG}}
        if: ${{ failure()  &&  env.ACTIONS_STEP_DEBUG == 'true' }}
        uses: mxschmitt/action-tmate@v3
        with:
          limit-access-to-actor: true
        timeout-minutes: 60


  Create_release:
    name: Create release
    if: >
      github.actor!='dependabot[bot]' &&
      github.event_name!='pull_request' &&
      ( github.ref_type=='tag' || github.ref_type=='branch' )
    needs:
      - "Client_build"
      - "Server_tests"
      - "Docker_image"

    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Fetch build
        id: fetch_artifact
        uses: actions/download-artifact@v4
        with:
          name: "sbs-build"
          path: "artifacts/"

      - name: Info
        run: |
          ls -la ${{steps.fetch_artifact.outputs.download-path}}
          sha1sum ${{steps.fetch_artifact.outputs.download-path}}/* || true
          sha256sum ${{steps.fetch_artifact.outputs.download-path}}/* || true

      - name: Create Release
        if: "github.ref_type=='tag'"
        uses: softprops/action-gh-release@v2
        with:
          files: "${{steps.fetch_artifact.outputs.download-path}}/*"

      - name: Advance latest tag
        if: "github.ref_type=='branch'"
        uses: EndBug/latest-tag@v1
        with:
          ref: "branch+${{github.ref_name}}"
          description: "Latest commit in branch ${{github.ref_name}}"

      - name: remove all previous "latest" releases
        if: "github.ref_type=='branch'"
        uses: dev-drprasad/delete-older-releases@v0.3.3
        with:
          keep_latest: 0
          delete_tag_pattern: "branch+${{github.ref_name}}"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Create Release for main/latest
        if: "github.ref_type=='branch'"
        uses: softprops/action-gh-release@v2
        with:
          name: "Latest from branch ${{github.ref_name}}"
          tag_name: "branch+${{github.ref_name}}"
          prerelease: true
          files: "${{steps.fetch_artifact.outputs.download-path}}/sbs.tar.xz"

      - name: Get token
        id: get_token
        uses: machine-learning-apps/actions-app-token@master
        with:
          APP_PEM: ${{ secrets.SRAM_ACTIONAPP_PEM }}
          APP_ID: ${{ secrets.SRAM_ACTIONAPP_APPID }}

      - name: Test new SBS build in SCZ-deploy's CI-runner
        if: "github.ref_name=='main'"
        uses: actions/github-script@v7
        with:
          github-token: ${{ steps.get_token.outputs.app_token }}
          script: |
            await github.rest.actions.createWorkflowDispatch({
              owner: 'SURFscz',
              repo: 'SRAM-deploy',
              workflow_id: 'ci-runner.yml',
              ref: 'main'
            })


  Schema_pr:
    name: Update schema cache

    runs-on: ubuntu-latest

    if: "github.ref == 'refs/heads/main'"

    services:
      mysql:
        image: mysql:5.7
        env:
          MYSQL_ROOT_PASSWORD: root
        ports:
          - 3306:3306
        options: --health-cmd="mysqladmin ping" --health-interval=10s --health-timeout=5s --health-retries=3

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup mysql server
        run: >
          mysql -uroot -proot -h127.0.0.1 -e "
            DROP DATABASE IF EXISTS sbs;
            CREATE DATABASE IF NOT EXISTS sbs DEFAULT CHARACTER SET utf8mb4 DEFAULT COLLATE utf8mb4_unicode_ci;
            CREATE USER 'sbs'@'%' IDENTIFIED BY 'sbs';
            GRANT ALL PRIVILEGES ON *.* TO 'sbs'@'%' WITH GRANT OPTION;
          "
      - name: Load SBS schema
        # not strictly necessary, but it avoids running 200+ migrations during tests
        run: |
          mysql -uroot -proot -h127.0.0.1 sbs < misc/sbs-db.sql

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: 'pip'
          cache-dependency-path: 'server/requirements/*.txt'

      - name: Install dependencies
        run: |
          python -m pip install pip setuptools wheel
          pip install --upgrade pip
          pip install -r ./server/requirements/test.txt

      - name: Run alembic migrations
        run: |
          cd server
          alembic --config migrations/alembic.ini upgrade head
          echo alembic_current=$(alembic --config migrations/alembic.ini current) >> "$GITHUB_ENV"
        env:
          CONFIG: "config/test_config.yml"

      - name: Dump latest database schema
        run: |
          echo "-- Dump of empty SBS database, alembic revision $alembic_current" > misc/sbs-db.sql
          mysqldump -h 127.0.0.1 -u sbs --password=sbs --skip-comments sbs | sed -E '${/^$/d;}' >> misc/sbs-db.sql

      - name: Create Pull Request
        uses: "peter-evans/create-pull-request@v6"
        with:
          add-paths: |
            misc/sbs-db.sql
          commit-message: "Update schema cache for Alembic revision ${{ env.alembic_current }}"
          branch: "update-schema-cache"
          title: "Update schema cache"
          body: |
            This PR updates the schema cache to the latest version.
            It was created by a GitHub Actions workflow.
